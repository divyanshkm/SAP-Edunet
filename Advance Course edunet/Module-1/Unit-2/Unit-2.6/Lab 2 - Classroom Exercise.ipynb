{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8c008f",
   "metadata": {},
   "source": [
    "# EDUNET FOUNDATION-Class Exercise Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c568c4a1",
   "metadata": {},
   "source": [
    "## LAB 2 - Demonstrating XG Boost on Credit Card Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70477f6a",
   "metadata": {},
   "source": [
    "### importing required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc547687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a66fa2",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a893e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c27dfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921933f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of our data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccde256e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of two classes in the target variable\n",
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25a984",
   "metadata": {},
   "source": [
    "Clearly the dataset is heavily imbalanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "771641d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset with all independent variables\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Creating the dataset with the dependent variable\n",
    "Y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72924cf7",
   "metadata": {},
   "source": [
    "* Split the dataset into train and test using stratified sampling on our dependent variable. \n",
    "* Using a stratified sampling ensures the distribution of dependent variable remains same across train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf22605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a49d2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train dataset :\n",
      "(227845, 30)\n",
      "\n",
      " The shape of test dataset :\n",
      "(56962, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of train dataset :\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\n The shape of test dataset :\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae33b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of classes of dependent variable in train :\n",
      "0    227451\n",
      "1       394\n",
      "Name: Class, dtype: int64\n",
      "\n",
      " Distribution of classes of dependent variable in test :\n",
      "0    56864\n",
      "1       98\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of classes of dependent variable in train :\")\n",
    "print(Y_train.value_counts())\n",
    "\n",
    "print(\"\\n Distribution of classes of dependent variable in test :\")\n",
    "print(Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "191fbae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.6-py3-none-win_amd64.whl (70.9 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\palwinder\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in c:\\users\\palwinder\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7968e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lightgbm and xgboost \n",
    "# import lightgbm as lgb \n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46b70ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data is stored in a DMatrix object \n",
    "#label is used to define our outcome variable\n",
    "#The data is stored in a DMatrix object Data Matrix used in XGBoost. DMatrix is an internal data structure that is used by XGBoost, which is optimized for both memory efficiency and training speed. You can construct DMatrix from multiple different sources of data.\n",
    "#\n",
    "dtrain=xgb.DMatrix(X_train,label=Y_train)\n",
    "dtest=xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "430609a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameters for xgboost\n",
    "parameters={'max_depth':7, 'eta':1, 'silent':1,'objective':'binary:logistic','eval_metric':'auc','learning_rate':.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a930fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:56:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training our model \n",
    "num_round=50\n",
    "from datetime import datetime \n",
    "start = datetime.now() \n",
    "xg=xgb.train(parameters,dtrain,num_round) \n",
    "stop = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f470c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now predicting our model on train set \n",
    "train_class_preds_probs=xg.predict(dtrain) \n",
    "#now predicting our model on test set \n",
    "test_class_preds_probs =xg.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7131366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227845"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of pred prob\n",
    "len(train_class_preds_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f60d77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation from thresold value\n",
    "train_class_preds = []\n",
    "test_class_preds = []\n",
    "for i in range(0,len(train_class_preds_probs)):\n",
    "  if train_class_preds_probs[i] >= 0.5:\n",
    "    train_class_preds.append(1)\n",
    "  else:\n",
    "    train_class_preds.append(0)\n",
    "\n",
    "for i in range(0,len(test_class_preds_probs)):\n",
    "  if test_class_preds_probs[i] >= 0.5:\n",
    "    test_class_preds.append(1)\n",
    "  else:\n",
    "    test_class_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34ae1085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04059012, 0.04059012, 0.04059012, 0.04059012, 0.04059012,\n",
       "       0.04059012, 0.04059012, 0.04059012, 0.04059012, 0.04059012,\n",
       "       0.04059012, 0.04059012, 0.04059012, 0.04059012, 0.04059012,\n",
       "       0.04059012, 0.04059012, 0.04059012, 0.04059012, 0.04059012],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the array of pred prob\n",
    "test_class_preds_probs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24f05dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of y train\n",
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86108a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227845"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lenght of train class pred\n",
    "len(train_class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa0ed132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on train data is  0.9997366630823586\n",
      "The accuracy on test data is  0.9994733330992591\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy scores\n",
    "train_accuracy_xgb = accuracy_score(train_class_preds,Y_train)\n",
    "test_accuracy_xgb = accuracy_score(test_class_preds,Y_test)\n",
    "\n",
    "print(\"The accuracy on train data is \", train_accuracy_xgb)\n",
    "print(\"The accuracy on test data is \", test_accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d88cd360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on test data is  0.9994733330992591\n",
      "The precision on test data is  0.7551020408163265\n",
      "The recall on test data is  0.925\n",
      "The f1 on test data is  0.8314606741573034\n",
      "The roc_score on train data is  0.9622890369536936\n"
     ]
    }
   ],
   "source": [
    "#model evaluation before gdcv\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "test_accuracy_xgb = accuracy_score(test_class_preds,Y_test)\n",
    "test_precision_xgb = precision_score(test_class_preds,Y_test)\n",
    "test_recall_score_xgb = recall_score(test_class_preds,Y_test)\n",
    "test_f1_score_xgb = f1_score(test_class_preds,Y_test)\n",
    "test_roc_score_xgb = roc_auc_score(test_class_preds,Y_test)\n",
    "\n",
    "print(\"The accuracy on test data is \", test_accuracy_xgb)\n",
    "print(\"The precision on test data is \", test_precision_xgb)\n",
    "print(\"The recall on test data is \", test_recall_score_xgb)\n",
    "print(\"The f1 on test data is \", test_f1_score_xgb)\n",
    "print(\"The roc_score on train data is \", test_roc_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63b5027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=0, gpu_id=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_bin=None,\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=5,\n",
       "                                     max_leaves=None, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=140, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(3, 10, 2),\n",
       "                         &#x27;min_child_weight&#x27;: range(1, 6, 2)},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=0, gpu_id=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_bin=None,\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=5,\n",
       "                                     max_leaves=None, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=140, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(3, 10, 2),\n",
       "                         &#x27;min_child_weight&#x27;: range(1, 6, 2)},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=140, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=140, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "              predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=0, gpu_id=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_bin=None,\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=5,\n",
       "                                     max_leaves=None, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=140, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(3, 10, 2),\n",
       "                         'min_child_weight': range(1, 6, 2)},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search cv for xgboost\n",
    "from xgboost import XGBClassifier\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='accuracy',n_jobs=-1, cv=3, verbose = 2)\n",
    "gsearch1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "186d860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995874388097498"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdcv score after training model on the data set\n",
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13e8c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal xgb\n",
    "optimal_xgb = gsearch1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "027b72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes\n",
    "train_class_preds = optimal_xgb.predict(X_train)\n",
    "test_class_preds = optimal_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21e83864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on train data is  0.9999780552568632\n",
      "The accuracy on test data is  0.9994908886626171\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy scores\n",
    "train_accuracy_xgb_tuned = accuracy_score(train_class_preds,Y_train)\n",
    "test_accuracy_xgb_tuned = accuracy_score(test_class_preds,Y_test)\n",
    "\n",
    "print(\"The accuracy on train data is \", train_accuracy_xgb_tuned)\n",
    "print(\"The accuracy on test data is \", test_accuracy_xgb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdd42458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on test data is  0.9994908886626171\n",
      "The precision on test data is  0.7448979591836735\n",
      "The recall on test data is  0.948051948051948\n",
      "The f1 on test data is  0.8342857142857143\n",
      "The roc_score on test data is  0.9738062324420768\n"
     ]
    }
   ],
   "source": [
    "#model score for xgboost\n",
    "test_accuracy_xgb_tuned = accuracy_score(test_class_preds,Y_test)\n",
    "test_precision_xgb_tuned = precision_score(test_class_preds,Y_test)\n",
    "test_recall_score_xgb_tuned = recall_score(test_class_preds,Y_test)\n",
    "test_f1_score_xgb_tuned = f1_score(test_class_preds,Y_test)\n",
    "test_roc_score_xgb_tuned = roc_auc_score(test_class_preds,Y_test)\n",
    "\n",
    "print(\"The accuracy on test data is \", test_accuracy_xgb_tuned)\n",
    "print(\"The precision on test data is \", test_precision_xgb_tuned)\n",
    "print(\"The recall on test data is \", test_recall_score_xgb_tuned)\n",
    "print(\"The f1 on test data is \", test_f1_score_xgb_tuned)\n",
    "print(\"The roc_score on test data is \", test_roc_score_xgb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c223a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.231481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.116204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.054628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.051229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.029050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.026017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.025606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.024993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    importance_xgb\n",
       "17        0.231481\n",
       "12        0.116204\n",
       "14        0.054628\n",
       "10        0.051229\n",
       "4         0.039966\n",
       "7         0.029050\n",
       "8         0.026017\n",
       "26        0.025606\n",
       "18        0.024993\n",
       "1         0.023745"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#important features respect to Xgb\n",
    "pd.DataFrame(optimal_xgb.feature_importances_,\n",
    "                                \n",
    "                                    columns=['importance_xgb']).sort_values('importance_xgb',\n",
    "                                                                        ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5168ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importances_xgb = pd.DataFrame(optimal_xgb.feature_importances_,\n",
    "                                    columns=['importance_xgb']).sort_values('importance_xgb',\n",
    "                                                                        ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70dd3e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot for the important feature selection by xgb\n",
    "plt.subplots(figsize=(17,6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(feature_importances_xgb.index, feature_importances_xgb['importance_xgb'],\n",
    "        color=\"b\",  align=\"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7926969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y pred after training the model by gdcv\n",
    "y_preds_proba_xgb = optimal_xgb.predict_proba(X_test)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25949fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot for the auc-roc for xgb\n",
    "import sklearn.metrics as metrics\n",
    "y_pred_proba = y_preds_proba_xgb\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(Y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
